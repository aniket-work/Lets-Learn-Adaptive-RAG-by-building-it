# ğŸ§  Adaptive RAG: Learn by Building

A comprehensive implementation of **Adaptive Retrieval-Augmented Generation (RAG)** that intelligently routes queries between vectorstore retrieval and web search based on query characteristics.

## ğŸ¯ What is Adaptive RAG?

Adaptive RAG is a smart approach that adjusts how information is retrieved and used based on the complexity and nature of a query. Instead of treating all queries the same way, it chooses the optimal strategy:

- **ğŸ“š Vectorstore Retrieval**: For questions answerable using indexed documents
- **ğŸŒ Web Search**: For questions requiring real-time or external information
- **ğŸ”„ Self-Correction**: Validates and improves responses through multiple evaluation layers

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User Query    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚  Router   â”‚ â—„â”€â”€â”€ Determines best data source
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜      (vectorstore vs web search)
          â”‚
     â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
     â”‚ Branch  â”‚
     â””â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”˜
       â”‚     â”‚
   â”Œâ”€â”€â”€â–¼â”€â” â”Œâ”€â–¼â”€â”€â”€â”€â”€â”€â”
   â”‚ RAG â”‚ â”‚ Web    â”‚
   â”‚     â”‚ â”‚ Search â”‚
   â””â”€â”¬â”€â”€â”€â”˜ â””â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
     â”‚       â”‚
     â””â”€â”€â”€â”¬â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚ Graders â”‚ â—„â”€â”€â”€ Validates relevance,
    â”‚         â”‚      hallucinations, and
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      answer quality
```

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone the repository
git clone https://github.com/your-username/adaptive-rag
cd adaptive-rag

# Install dependencies
pip install -r requirements.txt
```

### 2. Environment Setup

```bash
# Copy environment template
cp .env.example .env

# Edit .env file with your API keys
GROQ_API_KEY=your_groq_api_key_here
TAVILY_API_KEY=your_tavily_api_key_here
# Optional: For embeddings (if not using HuggingFace fallback)
# OPENAI_API_KEY=your_openai_api_key_here
```

### 3. Basic Usage

```python
from src import AdaptiveRAG, DocumentProcessor

# Initialize components
doc_processor = DocumentProcessor()
rag_system = AdaptiveRAG()

# Load your documents
documents = doc_processor.load_csv("path/to/your/data.csv")

# Set up the system
rag_system.setup_vectorstore(documents)

# Ask questions!
answer = rag_system.query("How does machine learning work?")
print(answer)
```

### 4. Run Examples

```bash
# Basic example
python examples/basic_example.py

# Evaluation example with built-in metrics
python examples/evaluation_example.py
```

## ğŸ“ Project Structure

```
adaptive-rag/
â”œâ”€â”€ src/                          # Core implementation
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ adaptive_rag.py          # Main RAG system
â”‚   â”œâ”€â”€ config.py                # Configuration settings
â”‚   â”œâ”€â”€ models.py                # Data models
â”‚   â”œâ”€â”€ router.py                # Question routing logic
â”‚   â”œâ”€â”€ retrieval.py             # Document retrieval & web search
â”‚   â”œâ”€â”€ rag_chain.py             # RAG generation chain
â”‚   â”œâ”€â”€ graders.py               # Response validation
â”‚   â”œâ”€â”€ evaluator.py             # Built-in evaluation system
â”‚   â””â”€â”€ document_processor.py    # Document loading & processing
â”œâ”€â”€ examples/                     # Usage examples
â”‚   â”œâ”€â”€ basic_example.py
â”‚   â””â”€â”€ evaluation_example.py
â”œâ”€â”€ data/                        # Data directory
â”œâ”€â”€ requirements.txt             # Dependencies
â”œâ”€â”€ .env.example                 # Environment template
â””â”€â”€ README.md                    # This file
```

## ğŸ”§ Core Components

### 1. Question Router
Routes queries to the appropriate data source based on content analysis:
- Analyzes query topics and context
- Routes to vectorstore for known topics
- Routes to web search for external/real-time information

### 2. Document Grader
Evaluates retrieved documents for relevance:
- Filters out irrelevant documents
- Ensures only contextually appropriate information is used

### 3. Hallucination Grader
Validates that generated responses are grounded in facts:
- Checks if answers are supported by retrieved documents
- Prevents fabricated or unsupported claims

### 4. Answer Grader
Ensures responses address the original question:
- Validates that answers are relevant and complete
- Triggers retry mechanisms if responses are inadequate

## ğŸš€ Key Features

- **ğŸ¦™ Groq-Powered**: Uses Groq's lightning-fast LLM inference with Llama3 models
- **ğŸ¯ Smart Routing**: Automatically chooses between vectorstore and web search
- **ğŸ“Š Built-in Evaluation**: Comprehensive metrics without external API dependencies
- **ğŸ”„ Self-Correction**: Multi-layer validation and response improvement
- **ğŸ› ï¸ Modular Design**: Easy to customize and extend
- **ğŸ’¡ Flexible Embeddings**: Supports OpenAI, HuggingFace, or custom embedding providers

## ğŸ“Š Evaluation

The system includes a **built-in evaluation framework** that provides comprehensive metrics without requiring external APIs:

```python
from src import SimpleEvaluator

# Initialize evaluator
evaluator = SimpleEvaluator(rag_system)

# Evaluate questions
questions = ["Your test questions here"]
results = evaluator.evaluate_batch(questions)

# Get detailed report
evaluator.print_detailed_report()

# Save results to CSV
evaluator.save_results_to_csv()
```

### Evaluation Metrics:
- â±ï¸ **Response Time**: How fast the system responds
- ğŸ”€ **Routing Analysis**: Vectorstore vs web search distribution
- ğŸ“ **Answer Quality**: Length, citations, context usage
- ğŸ“Š **Performance Stats**: Min/max response times and answer lengths

## âš™ï¸ Configuration

Customize the system behavior in `src/config.py`:

```python
class Config:
    # Model settings (Groq)
    DEFAULT_MODEL = "llama3-8b-8192"
    ROUTER_MODEL = "llama3-70b-8192"
    
    # Retrieval settings
    RETRIEVAL_K = 4  # Documents to retrieve
    WEB_SEARCH_K = 3  # Web search results
    
    # Document processing
    CHUNK_SIZE = 500
    CHUNK_OVERLAP = 0
```

## ğŸ¨ Customization

### Adding New Data Sources

1. **Custom Document Loaders**:
```python
from src.document_processor import DocumentProcessor

processor = DocumentProcessor()
# Add support for new file types
documents = processor.load_directory("./your_data/", "**/*.pdf")
```

2. **Custom Topics for Routing**:
```python
from src.router import QuestionRouter

router = QuestionRouter()
router.update_topics([
    "Your custom topic 1",
    "Your custom topic 2",
    # ... more topics
])
```

### Extending Evaluation

```python
# Use the built-in evaluator
from src import SimpleEvaluator

evaluator = SimpleEvaluator(rag_system)

# Add custom metrics or extend the evaluation
results = evaluator.evaluate_batch(questions)
report = evaluator.generate_report()

# Access detailed metrics
for result in evaluator.evaluation_results:
    print(f"Question: {result.question}")
    print(f"Route: {result.route_taken}")
    print(f"Response time: {result.response_time}s")
```

## ğŸ” How It Works

1. **Query Analysis**: The router analyzes the incoming question
2. **Source Selection**: Decides between vectorstore or web search
3. **Information Retrieval**: Fetches relevant information from chosen source
4. **Document Grading**: Filters retrieved documents for relevance
5. **Response Generation**: Creates answer using RAG chain
6. **Quality Validation**: Checks for hallucinations and answer quality
7. **Self-Correction**: Retries with query transformation if needed

## ğŸ“ˆ Performance Tips

- **Vectorstore Optimization**: Use appropriate chunk sizes for your domain
- **Model Selection**: Choose models based on speed vs. accuracy trade-offs
- **Caching**: Implement caching for frequently accessed documents
- **Batch Processing**: Process multiple queries together for efficiency

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Based on the research paper: [Adaptive RAG](https://arxiv.org/pdf/2403.14403)
- Built with [LangChain](https://langchain.com/) and [LangGraph](https://langchain-ai.github.io/langgraph/)
- Simple evaluation system with comprehensive metrics

## ğŸ“ Support

- ğŸ“§ Create an issue for bug reports or feature requests
- ğŸ’¬ Join discussions in the Issues section
- ğŸ“– Check the examples for common use cases

---

**Built with â¤ï¸ for the AI community**
